{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDswlIIseM7c",
        "outputId": "04fd2550-4093-460e-d8d2-3ed5c31e4ca3"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9EVH5dCeQdf",
        "outputId": "374e9b53-b0c7-425e-be0e-6777eb3059d3"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARBnsyL8gHFe",
        "outputId": "8c8ff666-71f3-42e8-c472-093648334d32"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ghaweJJg80t",
        "outputId": "24834c50-99b2-44c0-befa-6efa16667e07"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "url_front = 'https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%EC%B9%B4%EB%88%88&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=44&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start='\n",
        "\n",
        "visitCount = 0\n",
        "\n",
        "file = open('/content/gdrive/MyDrive/BigDataAnalaysis/naver-crawling.txt', 'w')\n",
        "\n",
        "for pageIndex in range(1, 302, 10): # 실습 시간을 고려하여 302까지만 실행 (31페이지)\n",
        "  pageUrl = '{0}{1}'.format(url_front, pageIndex)\n",
        "  html = urlopen(pageUrl)\n",
        "  bsObject = BeautifulSoup(html, 'html.parser')\n",
        "  for link in bsObject.find_all('a', {'class':'news_tit'}):\n",
        "    data = link.get('title') + '\\n'\n",
        "    file.write(data)\n",
        "\n",
        "  visitCount += 1\n",
        "  print('Read {0} page...'.format(visitCount))\n",
        "\n",
        "  time.sleep(3)\n",
        "file.close()\n",
        "print('모든 데이터가 수집되었습니다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzAD1kTCi-th",
        "outputId": "d23620ab-25ef-4f3c-98ab-ef8b763e1258"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQe8AfTps4Ht"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Twitter\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TboKOiSXuUwQ",
        "outputId": "6670958d-df3d-4787-ce3f-d3ee54b75c57"
      },
      "outputs": [],
      "source": [
        "# 수집한 데이터 title_list 리스트에 넣기\n",
        "title_list = []\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/BigDataAnalaysis/naver-crawling.txt\", 'r', encoding='utf-8') as file :\n",
        "    title_list = file.readlines()\n",
        "\n",
        "# 형태소 분석하여 sentences_tag 리스트에 넣기\n",
        "twitter = Twitter()\n",
        "sentences_tag = []\n",
        "\n",
        "for sentence in title_list :\n",
        "    morph = twitter.pos(sentence)\n",
        "    sentences_tag.append(morph)\n",
        "    print(morph)\n",
        "    print('-'*3)\n",
        "\n",
        "print(sentences_tag)\n",
        "print('\\n'*3)\n",
        "\n",
        "# 명사와 형용사만 구분하여 noun_adj_list 리스트에 넣기\n",
        "noun_adj_list = []\n",
        "\n",
        "for sentence1 in sentences_tag :\n",
        "    for word, tag in sentence1 :\n",
        "        if tag in ['Noun', 'Adjective'] :\n",
        "            noun_adj_list.append(word)\n",
        "\n",
        "# 형태소별 단어 카운트 및 상위 30개 단어 tags 리스트에 넣기\n",
        "counts = Counter(noun_adj_list)\n",
        "tags = counts.most_common(30)\n",
        "print(tags)\n",
        "\n",
        "# 한글 깨지는 문제 해결하기 위해 폰트 설정\n",
        "wc = WordCloud(font_path='/content/gdrive/MyDrive/BigDataAnalaysis/NanumGothic.ttf', background_color='white', width=800, height=600)\n",
        "\n",
        "# 워드 클라우드 생성\n",
        "cloud = wc.generate_from_frequencies(dict(tags))\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(cloud)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmx3WtSLue1O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
